# 实验三：数值积分实验报告

## 1. 实验目的
- 理解数值积分的基本原理
- 实现并比较矩形法和梯形法两种数值积分方法
- 分析不同积分方法的收敛性和精度
- 探究步长对数值积分精度的影响

## 2. 实验原理
### 2.1 问题描述
计算定积分：
$$
I = \int_{0}^1 \sqrt{1-x^2} d x
$$
该积分表示1/4圆的面积，其解析解为 $\frac{1}{4}\pi \approx 0.7853981633974483$。

### 2.2 数值方法
#### 2.2.1 矩形法（左矩形法）
将积分区间 $[a,b]$ 等分为 $N$ 个子区间，每个子区间长度为 $h=(b-a)/N$，用左端点函数值近似该子区间上的平均函数值：
$$
\int_a^b f(x)dx \approx h\sum_{k=0}^{N-1} f(x_k), \quad x_k = a + kh
$$

#### 2.2.2 梯形法
同样将积分区间等分为 $N$ 个子区间，但使用梯形面积近似每个子区间上的积分：
$$
\int_a^b f(x)dx \approx \frac{h}{2}[f(a) + 2\sum_{k=1}^{N-1}f(x_k) + f(b)]
$$

## 3. 实验结果
### 3.1 数值结果
（填写不同N值下的计算结果表格）
精确值: 1.5707963268
| N | 矩形法结果 | 矩形法相对误差 | 梯形法结果 | 梯形法相对误差 |
|---|------------|----------------|------------|----------------|
| 10 |      1.5185244144       |   3.33%       |    1.5185244144      |     3.33%         |
| 100 |     1.5691342555       |   0.106%      |    1.5691342555      |     0.106%        |
| 1000 |    1.5707437385       |   0.00335%    |    1.5707437385      |     0.00335%      |
| 10000 |   1.5707946637       |   0.000109%   |    1.5707946637      |     0.000109%     |

### 3.2 误差分析图
（插入误差-步长关系的对数图，并说明观察到的现象）
![image](https://github.com/user-attachments/assets/1e188366-a1c8-4a61-ace7-1d3475cd5556)
现象：矩形法的误差随着步长的减小（即 N 的增大）呈线性下降，符合 O(h) 的收敛阶数。梯形法的误差随着步长的减小呈二次方下降，符合 O(h²) 的收敛阶数。梯形法在相同步长下的误差明显小于矩形法，说明梯形法的收敛性更好。
## 4. 分析与讨论
### 4.1 收敛性分析
- 矩形法的收敛阶数：（填写并解释）
  A:矩形法的收敛阶数：约 1.00，符合理论预期的 O(h) 收敛阶数。
- 梯形法的收敛阶数：（填写并解释）
  A:梯形法的收敛阶数：约 2.00，符合理论预期的 O(h²) 收敛阶数。
- 两种方法收敛性的比较：（分析优劣）
  A:两种方法收敛性的比较：梯形法的收敛性明显优于矩形法，因为其误差下降速度更快。

### 4.2 精度分析
- 在相同N值下两种方法精度的比较
  A:梯形法的精度始终高于矩形法。
- 影响精度的主要因素分析
  A:步长 h 是影响精度的主要因素，步长越小，精度越高。此外，方法本身的收敛阶数也决定了其精度。
- 如何选择合适的N值以达到期望精度
  A:根据所需的精度和计算资源，选择合适的 N 值。梯形法在较小的 N 值下即可达到较高的精度，因此在实际应用中更推荐使用梯形法。

### 4.3 计算效率
- 计算时间随N的变化规律
  A:随着 N 的增大，计算时间线性增加。
- 精度和计算时间的权衡
  A:虽然增大 N 可以提高精度，但也会增加计算时间。在实际应用中，需要根据精度要求和时间限制选择合适的 N 值。

## 5. 结论
（总结本实验的主要发现，特别是关于两种方法的优缺点和适用场景）
A:梯形法的收敛性和精度均优于矩形法，更适合用于高精度的数值积分计算。步长 h 对数值积分的精度有显著影响，减小步长可以提高精度，但会增加计算时间。
## 6. 思考题
1. 为什么梯形法通常比矩形法更精确？
   A:梯形法通过使用梯形面积近似积分，考虑了区间端点的函数值，而矩形法仅使用左端点的函数值。梯形法的误差项为 O(h²)，而矩形法的误差项为 O(h)，因此梯形法的精度更高。
2. 如果被积函数在积分区间内有奇点（如 $\int_0^1 \frac{1}{\sqrt{x}}dx$），这些方法是否仍然适用？为什么？
   A:在被积函数存在奇点的情况下，矩形法和梯形法可能不再适用，因为这些方法假设函数在区间内光滑。奇点会导致函数值在某些点附近急剧变化，从而使得数值积分方法的误差增大。
3. 如何改进这些方法以获得更高的精度？
   A:可以通过减小步长 h 来提高精度

## 附录：代码实现
```python
def rectangle_method(f, a, b, N):
    """矩形法（左矩形法）计算积分
    
    参数:
        f (function): 被积函数
        a (float): 积分下限
        b (float): 积分上限
        N (int): 区间分割数
    
    返回:
        float: 积分近似值
    """
    h = (b - a) / N
    integral = 0.0
    for k in range(N):
        x_k = a + k * h
        integral += f(x_k) * h
    return integral

def trapezoid_method(f, a, b, N):
    """梯形法计算积分
    
    参数:
        f (function): 被积函数
        a (float): 积分下限
        b (float): 积分上限
        N (int): 区间分割数
    
    返回:
        float: 积分近似值
    """
    h = (b - a) / N
    integral = 0.5 * (f(a) + f(b)) * h
    for k in range(1, N):
        x_k = a + k * h
        integral += f(x_k) * h
    return integral

def calculate_errors(a, b, exact_value):
    """计算不同N值下各方法的误差
    
    参数:
        a (float): 积分下限
        b (float): 积分上限
        exact_value (float): 积分精确值
    
    返回:
        tuple: (N_values, h_values, rect_errors, trap_errors)
    """
    N_values = [10, 100, 1000, 10000]
    h_values = []
    rect_errors = []
    trap_errors = []
    
    for N in N_values:
        h = (b - a) / N
        h_values.append(h)
        
        rect_result = rectangle_method(f, a, b, N)
        trap_result = trapezoid_method(f, a, b, N)
        
        rect_error = abs(rect_result - exact_value) / exact_value
        trap_error = abs(trap_result - exact_value) / exact_value
        
        rect_errors.append(rect_error)
        trap_errors.append(trap_error)
    
    return N_values, h_values, rect_errors, trap_errors

def plot_errors(h_values, rect_errors, trap_errors):
    """绘制误差-步长关系图
    
    参数:
        h_values (list): 步长列表
        rect_errors (list): 矩形法误差列表
        trap_errors (list): 梯形法误差列表
    """
    plt.figure(figsize=(10, 6))
    plt.loglog(h_values, rect_errors, 'o-', label='矩形法')
    plt.loglog(h_values, trap_errors, 's-', label='梯形法')
    
    # 添加参考线
    plt.loglog(h_values, [h**1 for h in h_values], '--', label='O(h)')
    plt.loglog(h_values, [h**2 for h in h_values], '--', label='O(h²)')
    
    plt.xlabel('步长 h')
    plt.ylabel('相对误差')
    plt.title('误差-步长关系图')
    plt.legend()
    plt.grid(True)

def print_results(N_values, rect_results, trap_results, exact_value):
    """打印计算结果表格
    
    参数:
        N_values (list): 分割数列表
        rect_results (list): 矩形法结果列表
        trap_results (list): 梯形法结果列表
        exact_value (float): 精确值
    """
    print("\n计算结果表格:")
    print(f"{'N':<10}{'矩形法近似值':<20}{'梯形法近似值':<20}{'精确值':<20}")
    for i, N in enumerate(N_values):
        print(f"{N:<10}{rect_results[i]:<20.10f}{trap_results[i]:<20.10f}{exact_value:<20.10f}")

def time_performance_test(a, b, max_time=1.0):
    """测试在限定时间内各方法能达到的最高精度
    
    参数:
        a (float): 积分下限
        b (float): 积分上限
        max_time (float): 最大允许时间（秒）
    """
    exact_value = 0.5 * np.pi
    N = 10
    rect_time = 0
    trap_time = 0
    
    while rect_time < max_time or trap_time < max_time:
        start_time = time.time()
        rectangle_method(f, a, b, N)
        rect_time = time.time() - start_time
        
        start_time = time.time()
        trapezoid_method(f, a, b, N)
        trap_time = time.time() - start_time
        
        if rect_time >= max_time or trap_time >= max_time:
            break
        
        N *= 10
    
    rect_result = rectangle_method(f, a, b, N)
    trap_result = trapezoid_method(f, a, b, N)
    
    rect_error = abs(rect_result - exact_value) / exact_value
    trap_error = abs(trap_result - exact_value) / exact_value
    
    print("\n时间性能测试结果:")
    print(f"矩形法在 {max_time} 秒内达到的最高精度: {rect_error:.10f} (N={N})")
    print(f"梯形法在 {max_time} 秒内达到的最高精度: {trap_error:.10f} (N={N})")

def calculate_convergence_rate(h_values, errors):
    """计算收敛阶数
    
    参数:
        h_values (list): 步长列表
        errors (list): 误差列表
    
    返回:
        float: 收敛阶数
    """
    log_h = np.log(h_values)
    log_error = np.log(errors)
    
    # 使用最小二乘法拟合
    A = np.vstack([log_h, np.ones(len(log_h))]).T
    slope, _ = np.linalg.lstsq(A, log_error, rcond=None)[0]
    
    return slope
```
